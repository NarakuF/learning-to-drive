{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"gl2675.ipynb","provenance":[{"file_id":"1ood2pVdpGj7msJ0QmebVCBZaHjmjhtcF","timestamp":1570514240668}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5QRVsTmk8VqU","colab_type":"text"},"source":["# Getting Started:\n","## A simple driving model training and evaluation pipeline using the Drive360 dataset and PyTorch."]},{"cell_type":"markdown","metadata":{"id":"6bGwWWJc8VqV","colab_type":"text"},"source":["## Loading data from Drive360 dataset."]},{"cell_type":"markdown","metadata":{"id":"8cLew-HN8VqV","colab_type":"text"},"source":["The **dataset.py** file contains the 3 classes necessary for creating a Drive360Loader. Using the **config.json** file to specify the location of the csv and data directory, we can generate phase (train, validation, test) specific data loaders that can output samples from each set. Adjust the **dataset.py** to your preferred training framework."]},{"cell_type":"code","metadata":{"id":"DFtbx9E-EvmC","colab_type":"code","outputId":"62950745-1951-424d-922d-975f72714002","executionInfo":{"status":"ok","timestamp":1570689290119,"user_tz":240,"elapsed":4229,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y4it0hhTWhXL","colab_type":"code","outputId":"e0bf976f-c2d9-4f69-a049-0ba46760782f","executionInfo":{"status":"ok","timestamp":1570689406898,"user_tz":240,"elapsed":1439,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["import os\n","\n","root_path = \"/content/drive/My Drive/Competition/\"\n","os.chdir(root_path)\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["config_gl2675.json  dataset.py\t\t  __pycache__\t    yw3373_config.json\n","config.json\t    GettingStarted.ipynb  requirements.txt  yw3373.ipynb\n","data\t\t    gl2675.ipynb\t  Sample3\n","dataset_gl2675.py   model\t\t  submission.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AsjjLBZ-8VqW","colab_type":"code","outputId":"a43d6bc5-4780-4fa0-bbee-2e9836ba46ba","executionInfo":{"status":"ok","timestamp":1570689409419,"user_tz":240,"elapsed":1560,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["import json\n","from dataset import Drive360Loader\n","\n","# load the config.json file that specifies data \n","# location parameters and other hyperparameters \n","# required.\n","config = json.load(open('./config_gl2675.json'))\n","\n","# create a train, validation and test data loader\n","train_loader = Drive360Loader(config, 'train')\n","validation_loader = Drive360Loader(config, 'validation')\n","test_loader = Drive360Loader(config, 'test')\n","\n","# print the data (keys) available for use. See full \n","# description of each data type in the documents.\n","print('Loaded train loader with the following data available as a dict.')\n","print(train_loader.drive360.dataframe.keys())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Phase: train # of data: 35591\n","Phase: validation # of data: 2342\n","Phase: test # of data: 6369\n","Loaded train loader with the following data available as a dict.\n","Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'canSteering',\n","       'canSpeed', 'chapter'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iWNBEr4D8VqZ","colab_type":"text"},"source":["## Training a basic driving model"]},{"cell_type":"markdown","metadata":{"id":"9ergd-El8VqZ","colab_type":"text"},"source":["Create your driving model. This is specific to your learning framework. \n","\n","Below we give a very basic dummy model that uses the front facing camera and a resnet34 + LSTM architecture to predict canSteering and canSpeed. "]},{"cell_type":"code","metadata":{"id":"U1ndfRfd8Vqa","colab_type":"code","colab":{}},"source":["from torchvision import models\n","import torch.nn as nn\n","import torch\n","\n","class SomeDrivingModel(nn.Module):\n","    def __init__(self):\n","        super(SomeDrivingModel, self).__init__()\n","        final_concat_size = 0\n","        \n","        # Main CNN\n","        cnn = models.resnet34(pretrained=True)\n","        self.features = nn.Sequential(*list(cnn.children())[:-1])\n","        self.intermediate = nn.Sequential(nn.Linear(\n","                          cnn.fc.in_features, 128),\n","                          nn.ReLU())\n","        final_concat_size += 128\n","\n","        # Main LSTM\n","        self.lstm = nn.LSTM(input_size=128,\n","                            hidden_size=64,\n","                            num_layers=3,\n","                            batch_first=False)\n","        final_concat_size += 64\n","        \n","        # Angle Regressor\n","        self.control_angle = nn.Sequential(\n","            nn.Linear(final_concat_size, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 1)\n","        )\n","        # Speed Regressor\n","        self.control_speed = nn.Sequential(\n","            nn.Linear(final_concat_size, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 1)\n","        )\n","    \n","    def forward(self, data):\n","        module_outputs = []\n","        lstm_i = []\n","        # Loop through temporal sequence of\n","        # front facing camera images and pass \n","        # through the cnn.\n","        for k, v in data['cameraFront'].items():\n","            v = v.cuda()\n","            x = self.features(v)\n","            x = x.view(x.size(0), -1)\n","            x = self.intermediate(x)\n","            lstm_i.append(x)\n","            # feed the current front facing camera\n","            # output directly into the \n","            # regression networks.\n","            if k == 0:\n","                module_outputs.append(x)\n","\n","        # Feed temporal outputs of CNN into LSTM\n","        i_lstm, _ = self.lstm(torch.stack(lstm_i))\n","        module_outputs.append(i_lstm[-1])\n","        \n","        # Concatenate current image CNN output \n","        # and LSTM output.\n","        x_cat = torch.cat(module_outputs, dim=-1)\n","        \n","        # Feed concatenated outputs into the \n","        # regession networks.\n","        prediction = {'canSteering': torch.squeeze(self.control_angle(x_cat)),\n","                      'canSpeed': torch.squeeze(self.control_speed(x_cat))}\n","        return prediction\n","\n","# Create your own driving model, this is\n","#  a very basic one. \n","model = SomeDrivingModel().cuda()\n","MODEL_PATH = './model/gl2675.pth'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VldD5jyE8Vqb","colab_type":"text"},"source":["A basic training procedure that iterates over the train_loader and feeds each sample into our dummy model, subsequently calculates loss. We kill after 20 batches just"]},{"cell_type":"code","metadata":{"id":"THYSqolv8Vqb","colab_type":"code","outputId":"d77515c2-f121-401d-f7cd-3ead919410a5","executionInfo":{"status":"ok","timestamp":1570685509845,"user_tz":240,"elapsed":3698292,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import torch.optim as optim\n","\n","criterion = nn.SmoothL1Loss()\n","optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n","model.train()\n","for epoch in range(1):\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        prediction = model(data)\n","        \n","        # Ony optimizing for canSpeed at the moment\n","        # add canSteering to optimize simulatenously.\n","        loss_speed = criterion(prediction['canSpeed'], target['canSpeed'].cuda())\n","        loss_steer = criterion(prediction['canSteering'], target['canSteering'].cuda())\n","        loss = loss_speed + loss_steer\n","        loss.backward()\n","        optimizer.step()\n","        # print statistics\n","        running_loss += loss.item()\n","        if batch_idx % 2 == 1:  \n","            print('[epoch: %d, batch:  %5d] loss: %.5f' %\n","                  (epoch + 1, batch_idx + 1, running_loss / 2.0))\n","            running_loss = 0.0\n","        # Remove this when actually training. \n","        # Used to terminate early. \n","        '''\n","        if batch_idx >= 4: \n","            break\n","        '''\n","            \n","torch.save(model, MODEL_PATH)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[epoch: 1, batch:      2] loss: 0.42882\n","[epoch: 1, batch:      4] loss: 0.37929\n","[epoch: 1, batch:      6] loss: 0.46152\n","[epoch: 1, batch:      8] loss: 0.46333\n","[epoch: 1, batch:     10] loss: 0.47600\n","[epoch: 1, batch:     12] loss: 0.52426\n","[epoch: 1, batch:     14] loss: 0.44902\n","[epoch: 1, batch:     16] loss: 0.50589\n","[epoch: 1, batch:     18] loss: 0.53189\n","[epoch: 1, batch:     20] loss: 0.53663\n","[epoch: 1, batch:     22] loss: 0.35293\n","[epoch: 1, batch:     24] loss: 0.45092\n","[epoch: 1, batch:     26] loss: 0.52243\n","[epoch: 1, batch:     28] loss: 0.50144\n","[epoch: 1, batch:     30] loss: 0.55709\n","[epoch: 1, batch:     32] loss: 0.48640\n","[epoch: 1, batch:     34] loss: 0.39149\n","[epoch: 1, batch:     36] loss: 0.61570\n","[epoch: 1, batch:     38] loss: 0.51397\n","[epoch: 1, batch:     40] loss: 0.51559\n","[epoch: 1, batch:     42] loss: 0.46320\n","[epoch: 1, batch:     44] loss: 0.55532\n","[epoch: 1, batch:     46] loss: 0.52513\n","[epoch: 1, batch:     48] loss: 0.52913\n","[epoch: 1, batch:     50] loss: 0.50626\n","[epoch: 1, batch:     52] loss: 0.51540\n","[epoch: 1, batch:     54] loss: 0.57595\n","[epoch: 1, batch:     56] loss: 0.51793\n","[epoch: 1, batch:     58] loss: 0.45025\n","[epoch: 1, batch:     60] loss: 0.49603\n","[epoch: 1, batch:     62] loss: 0.54585\n","[epoch: 1, batch:     64] loss: 0.53785\n","[epoch: 1, batch:     66] loss: 0.64235\n","[epoch: 1, batch:     68] loss: 0.53138\n","[epoch: 1, batch:     70] loss: 0.50548\n","[epoch: 1, batch:     72] loss: 0.41817\n","[epoch: 1, batch:     74] loss: 0.49167\n","[epoch: 1, batch:     76] loss: 0.42870\n","[epoch: 1, batch:     78] loss: 0.60543\n","[epoch: 1, batch:     80] loss: 0.64138\n","[epoch: 1, batch:     82] loss: 0.43972\n","[epoch: 1, batch:     84] loss: 0.41895\n","[epoch: 1, batch:     86] loss: 0.57263\n","[epoch: 1, batch:     88] loss: 0.51926\n","[epoch: 1, batch:     90] loss: 0.56117\n","[epoch: 1, batch:     92] loss: 0.49244\n","[epoch: 1, batch:     94] loss: 0.53108\n","[epoch: 1, batch:     96] loss: 0.52895\n","[epoch: 1, batch:     98] loss: 0.59531\n","[epoch: 1, batch:    100] loss: 0.43054\n","[epoch: 1, batch:    102] loss: 0.44772\n","[epoch: 1, batch:    104] loss: 0.57261\n","[epoch: 1, batch:    106] loss: 0.48189\n","[epoch: 1, batch:    108] loss: 0.59311\n","[epoch: 1, batch:    110] loss: 0.68766\n","[epoch: 1, batch:    112] loss: 0.49727\n","[epoch: 1, batch:    114] loss: 0.44842\n","[epoch: 1, batch:    116] loss: 0.49917\n","[epoch: 1, batch:    118] loss: 0.42971\n","[epoch: 1, batch:    120] loss: 0.54424\n","[epoch: 1, batch:    122] loss: 0.51773\n","[epoch: 1, batch:    124] loss: 0.45575\n","[epoch: 1, batch:    126] loss: 0.46392\n","[epoch: 1, batch:    128] loss: 0.44970\n","[epoch: 1, batch:    130] loss: 0.48857\n","[epoch: 1, batch:    132] loss: 0.51042\n","[epoch: 1, batch:    134] loss: 0.40062\n","[epoch: 1, batch:    136] loss: 0.46338\n","[epoch: 1, batch:    138] loss: 0.56909\n","[epoch: 1, batch:    140] loss: 0.45766\n","[epoch: 1, batch:    142] loss: 0.48969\n","[epoch: 1, batch:    144] loss: 0.53377\n","[epoch: 1, batch:    146] loss: 0.45154\n","[epoch: 1, batch:    148] loss: 0.46966\n","[epoch: 1, batch:    150] loss: 0.50550\n","[epoch: 1, batch:    152] loss: 0.47797\n","[epoch: 1, batch:    154] loss: 0.46794\n","[epoch: 1, batch:    156] loss: 0.57091\n","[epoch: 1, batch:    158] loss: 0.45436\n","[epoch: 1, batch:    160] loss: 0.49951\n","[epoch: 1, batch:    162] loss: 0.50852\n","[epoch: 1, batch:    164] loss: 0.46165\n","[epoch: 1, batch:    166] loss: 0.47614\n","[epoch: 1, batch:    168] loss: 0.47684\n","[epoch: 1, batch:    170] loss: 0.41811\n","[epoch: 1, batch:    172] loss: 0.41412\n","[epoch: 1, batch:    174] loss: 0.51517\n","[epoch: 1, batch:    176] loss: 0.52269\n","[epoch: 1, batch:    178] loss: 0.49040\n","[epoch: 1, batch:    180] loss: 0.50837\n","[epoch: 1, batch:    182] loss: 0.60738\n","[epoch: 1, batch:    184] loss: 0.54098\n","[epoch: 1, batch:    186] loss: 0.49116\n","[epoch: 1, batch:    188] loss: 0.43625\n","[epoch: 1, batch:    190] loss: 0.56063\n","[epoch: 1, batch:    192] loss: 0.50792\n","[epoch: 1, batch:    194] loss: 0.40009\n","[epoch: 1, batch:    196] loss: 0.48039\n","[epoch: 1, batch:    198] loss: 0.59500\n","[epoch: 1, batch:    200] loss: 0.49394\n","[epoch: 1, batch:    202] loss: 0.55531\n","[epoch: 1, batch:    204] loss: 0.57382\n","[epoch: 1, batch:    206] loss: 0.59247\n","[epoch: 1, batch:    208] loss: 0.47036\n","[epoch: 1, batch:    210] loss: 0.41442\n","[epoch: 1, batch:    212] loss: 0.49213\n","[epoch: 1, batch:    214] loss: 0.53990\n","[epoch: 1, batch:    216] loss: 0.49694\n","[epoch: 1, batch:    218] loss: 0.58596\n","[epoch: 1, batch:    220] loss: 0.44210\n","[epoch: 1, batch:    222] loss: 0.55622\n","[epoch: 1, batch:    224] loss: 0.48581\n","[epoch: 1, batch:    226] loss: 0.52221\n","[epoch: 1, batch:    228] loss: 0.48784\n","[epoch: 1, batch:    230] loss: 0.52758\n","[epoch: 1, batch:    232] loss: 0.45390\n","[epoch: 1, batch:    234] loss: 0.54657\n","[epoch: 1, batch:    236] loss: 0.46215\n","[epoch: 1, batch:    238] loss: 0.60528\n","[epoch: 1, batch:    240] loss: 0.48633\n","[epoch: 1, batch:    242] loss: 0.57542\n","[epoch: 1, batch:    244] loss: 0.57235\n","[epoch: 1, batch:    246] loss: 0.59911\n","[epoch: 1, batch:    248] loss: 0.60181\n","[epoch: 1, batch:    250] loss: 0.37396\n","[epoch: 1, batch:    252] loss: 0.33456\n","[epoch: 1, batch:    254] loss: 0.44402\n","[epoch: 1, batch:    256] loss: 0.53234\n","[epoch: 1, batch:    258] loss: 0.45417\n","[epoch: 1, batch:    260] loss: 0.58189\n","[epoch: 1, batch:    262] loss: 0.54772\n","[epoch: 1, batch:    264] loss: 0.44277\n","[epoch: 1, batch:    266] loss: 0.36643\n","[epoch: 1, batch:    268] loss: 0.63609\n","[epoch: 1, batch:    270] loss: 0.60879\n","[epoch: 1, batch:    272] loss: 0.53453\n","[epoch: 1, batch:    274] loss: 0.47073\n","[epoch: 1, batch:    276] loss: 0.56295\n","[epoch: 1, batch:    278] loss: 0.51979\n","[epoch: 1, batch:    280] loss: 0.46602\n","[epoch: 1, batch:    282] loss: 0.49469\n","[epoch: 1, batch:    284] loss: 0.43181\n","[epoch: 1, batch:    286] loss: 0.48065\n","[epoch: 1, batch:    288] loss: 0.57994\n","[epoch: 1, batch:    290] loss: 0.41588\n","[epoch: 1, batch:    292] loss: 0.49228\n","[epoch: 1, batch:    294] loss: 0.49236\n","[epoch: 1, batch:    296] loss: 0.58894\n","[epoch: 1, batch:    298] loss: 0.46948\n","[epoch: 1, batch:    300] loss: 0.50506\n","[epoch: 1, batch:    302] loss: 0.44548\n","[epoch: 1, batch:    304] loss: 0.56536\n","[epoch: 1, batch:    306] loss: 0.46567\n","[epoch: 1, batch:    308] loss: 0.42995\n","[epoch: 1, batch:    310] loss: 0.50703\n","[epoch: 1, batch:    312] loss: 0.42999\n","[epoch: 1, batch:    314] loss: 0.39544\n","[epoch: 1, batch:    316] loss: 0.40127\n","[epoch: 1, batch:    318] loss: 0.48062\n","[epoch: 1, batch:    320] loss: 0.49170\n","[epoch: 1, batch:    322] loss: 0.51471\n","[epoch: 1, batch:    324] loss: 0.45747\n","[epoch: 1, batch:    326] loss: 0.38588\n","[epoch: 1, batch:    328] loss: 0.52009\n","[epoch: 1, batch:    330] loss: 0.48405\n","[epoch: 1, batch:    332] loss: 0.59248\n","[epoch: 1, batch:    334] loss: 0.60027\n","[epoch: 1, batch:    336] loss: 0.50872\n","[epoch: 1, batch:    338] loss: 0.50061\n","[epoch: 1, batch:    340] loss: 0.43141\n","[epoch: 1, batch:    342] loss: 0.44941\n","[epoch: 1, batch:    344] loss: 0.41807\n","[epoch: 1, batch:    346] loss: 0.49865\n","[epoch: 1, batch:    348] loss: 0.48062\n","[epoch: 1, batch:    350] loss: 0.54800\n","[epoch: 1, batch:    352] loss: 0.45565\n","[epoch: 1, batch:    354] loss: 0.47242\n","[epoch: 1, batch:    356] loss: 0.52355\n","[epoch: 1, batch:    358] loss: 0.50470\n","[epoch: 1, batch:    360] loss: 0.41718\n","[epoch: 1, batch:    362] loss: 0.44057\n","[epoch: 1, batch:    364] loss: 0.60672\n","[epoch: 1, batch:    366] loss: 0.53288\n","[epoch: 1, batch:    368] loss: 0.51077\n","[epoch: 1, batch:    370] loss: 0.53819\n","[epoch: 1, batch:    372] loss: 0.59491\n","[epoch: 1, batch:    374] loss: 0.46553\n","[epoch: 1, batch:    376] loss: 0.38891\n","[epoch: 1, batch:    378] loss: 0.48195\n","[epoch: 1, batch:    380] loss: 0.57112\n","[epoch: 1, batch:    382] loss: 0.63739\n","[epoch: 1, batch:    384] loss: 0.48317\n","[epoch: 1, batch:    386] loss: 0.45725\n","[epoch: 1, batch:    388] loss: 0.52383\n","[epoch: 1, batch:    390] loss: 0.47365\n","[epoch: 1, batch:    392] loss: 0.46506\n","[epoch: 1, batch:    394] loss: 0.50104\n","[epoch: 1, batch:    396] loss: 0.47418\n","[epoch: 1, batch:    398] loss: 0.44202\n","[epoch: 1, batch:    400] loss: 0.48760\n","[epoch: 1, batch:    402] loss: 0.48403\n","[epoch: 1, batch:    404] loss: 0.60808\n","[epoch: 1, batch:    406] loss: 0.41834\n","[epoch: 1, batch:    408] loss: 0.60255\n","[epoch: 1, batch:    410] loss: 0.50886\n","[epoch: 1, batch:    412] loss: 0.40242\n","[epoch: 1, batch:    414] loss: 0.51051\n","[epoch: 1, batch:    416] loss: 0.56641\n","[epoch: 1, batch:    418] loss: 0.54822\n","[epoch: 1, batch:    420] loss: 0.51438\n","[epoch: 1, batch:    422] loss: 0.56133\n","[epoch: 1, batch:    424] loss: 0.46138\n","[epoch: 1, batch:    426] loss: 0.42973\n","[epoch: 1, batch:    428] loss: 0.60575\n","[epoch: 1, batch:    430] loss: 0.52374\n","[epoch: 1, batch:    432] loss: 0.47199\n","[epoch: 1, batch:    434] loss: 0.59181\n","[epoch: 1, batch:    436] loss: 0.60765\n","[epoch: 1, batch:    438] loss: 0.64374\n","[epoch: 1, batch:    440] loss: 0.49789\n","[epoch: 1, batch:    442] loss: 0.42484\n","[epoch: 1, batch:    444] loss: 0.53621\n","[epoch: 1, batch:    446] loss: 0.53019\n","[epoch: 1, batch:    448] loss: 0.39394\n","[epoch: 1, batch:    450] loss: 0.48972\n","[epoch: 1, batch:    452] loss: 0.47461\n","[epoch: 1, batch:    454] loss: 0.45337\n","[epoch: 1, batch:    456] loss: 0.47516\n","[epoch: 1, batch:    458] loss: 0.48078\n","[epoch: 1, batch:    460] loss: 0.54041\n","[epoch: 1, batch:    462] loss: 0.43478\n","[epoch: 1, batch:    464] loss: 0.51725\n","[epoch: 1, batch:    466] loss: 0.52122\n","[epoch: 1, batch:    468] loss: 0.46643\n","[epoch: 1, batch:    470] loss: 0.50627\n","[epoch: 1, batch:    472] loss: 0.46238\n","[epoch: 1, batch:    474] loss: 0.45156\n","[epoch: 1, batch:    476] loss: 0.52472\n","[epoch: 1, batch:    478] loss: 0.55104\n","[epoch: 1, batch:    480] loss: 0.50584\n","[epoch: 1, batch:    482] loss: 0.43033\n","[epoch: 1, batch:    484] loss: 0.45839\n","[epoch: 1, batch:    486] loss: 0.47738\n","[epoch: 1, batch:    488] loss: 0.44923\n","[epoch: 1, batch:    490] loss: 0.48831\n","[epoch: 1, batch:    492] loss: 0.45168\n","[epoch: 1, batch:    494] loss: 0.47955\n","[epoch: 1, batch:    496] loss: 0.51549\n","[epoch: 1, batch:    498] loss: 0.58831\n","[epoch: 1, batch:    500] loss: 0.46235\n","[epoch: 1, batch:    502] loss: 0.53524\n","[epoch: 1, batch:    504] loss: 0.42488\n","[epoch: 1, batch:    506] loss: 0.44500\n","[epoch: 1, batch:    508] loss: 0.54588\n","[epoch: 1, batch:    510] loss: 0.49984\n","[epoch: 1, batch:    512] loss: 0.46893\n","[epoch: 1, batch:    514] loss: 0.40002\n","[epoch: 1, batch:    516] loss: 0.58789\n","[epoch: 1, batch:    518] loss: 0.45724\n","[epoch: 1, batch:    520] loss: 0.52893\n","[epoch: 1, batch:    522] loss: 0.51407\n","[epoch: 1, batch:    524] loss: 0.43868\n","[epoch: 1, batch:    526] loss: 0.50046\n","[epoch: 1, batch:    528] loss: 0.46963\n","[epoch: 1, batch:    530] loss: 0.52136\n","[epoch: 1, batch:    532] loss: 0.48798\n","[epoch: 1, batch:    534] loss: 0.41700\n","[epoch: 1, batch:    536] loss: 0.44254\n","[epoch: 1, batch:    538] loss: 0.61497\n","[epoch: 1, batch:    540] loss: 0.36378\n","[epoch: 1, batch:    542] loss: 0.49327\n","[epoch: 1, batch:    544] loss: 0.53444\n","[epoch: 1, batch:    546] loss: 0.55361\n","[epoch: 1, batch:    548] loss: 0.41621\n","[epoch: 1, batch:    550] loss: 0.43815\n","[epoch: 1, batch:    552] loss: 0.48174\n","[epoch: 1, batch:    554] loss: 0.60260\n","[epoch: 1, batch:    556] loss: 0.43487\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SomeDrivingModel. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"sZCORhoHK9NI","colab_type":"text"},"source":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SomeDrivingModel. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \""]},{"cell_type":"markdown","metadata":{"id":"oWPsgF2E8Vqd","colab_type":"text"},"source":["## Local evaluation of the model."]},{"cell_type":"code","metadata":{"id":"zPqD1Tt98Vqe","colab_type":"code","outputId":"fe10d93d-726a-47c4-96c4-36de6440cf88","executionInfo":{"status":"ok","timestamp":1570689496293,"user_tz":240,"elapsed":57684,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import numpy as np\n","model = torch.load(MODEL_PATH)\n","model.eval()\n","with torch.no_grad():\n","    for batch_idx, (data, target) in enumerate(validation_loader):\n","        prediction = model(data)\n","        # Again only evaluating the canSpeed \n","        # predictions, add canSteering when \n","        # jointly training.\n","        diff = prediction['canSpeed'].cuda() - target['canSpeed'].cuda()\n","        mse = torch.mean(torch.mul(diff, diff))\n","        print(mse)\n","        # Used to terminate early, remove.\n","        if batch_idx >= 2: \n","            break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(1.0542, device='cuda:0')\n","tensor(1.0954, device='cuda:0')\n","tensor(1.0632, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ryITCGoz8Vqf","colab_type":"text"},"source":["## Creating a submission file."]},{"cell_type":"code","metadata":{"id":"wc2ue2_Z8Vqf","colab_type":"code","colab":{}},"source":["normalize_targets = config['target']['normalize']\n","target_mean = config['target']['mean']\n","target_std = config['target']['std']\n","\n","def add_results(results, output):\n","    steering = np.squeeze(output['canSteering'].cpu().data.numpy())\n","    speed = np.squeeze(output['canSpeed'].cpu().data.numpy())\n","    if normalize_targets:\n","        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n","        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n","    if np.isscalar(steering):\n","        steering = [steering]\n","    if np.isscalar(speed):\n","        speed = [speed]\n","    results['canSteering'].extend(steering)\n","    results['canSpeed'].extend(speed)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Auh2-jMn8Vqh","colab_type":"text"},"source":["We use pandas to create a submission file which is simply a 2-column csv with a canSteering and canSpeed prediction for each row in the **drive360_test.csv** a total of 305437 rows/predictions not including the header. See the **sample_submission.csv** file as an example.\n","\n","IMPORTANT: for the test phase indices will start 10s (100 samples) into each chapter this is to allow challenge participants to experiment with different temporal settings of data input. If challenge participants have a greater temporal length than 10s for each training sample, then they must write a custom function here. Please check out the **dataset.py** file for additional explanation."]},{"cell_type":"code","metadata":{"id":"MseEEERwbj1Y","colab_type":"code","outputId":"ebc94457-95a2-4bf8-e4fc-927d9c276c21","executionInfo":{"status":"ok","timestamp":1570689395794,"user_tz":240,"elapsed":1483,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!pwd"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Competition\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h74vTYau8Vqi","colab_type":"code","outputId":"00a4ea9b-20e3-426e-e6fe-97bb1de4e15d","executionInfo":{"status":"ok","timestamp":1570690658769,"user_tz":240,"elapsed":41374,"user":{"displayName":"Guandong Liu","photoUrl":"","userId":"16878029981728163858"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","import torch\n","MODEL_PATH = './model/gl2675.pth'\n","model = torch.load(MODEL_PATH)\n","file = './submission.csv'\n","results = {'canSteering': [],\n","           'canSpeed': []}\n","i = 0\n","with torch.no_grad():\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","        prediction = model(data)\n","        \n","        add_results(results, prediction)\n","        i += 1\n","        if i % 10 == 0:\n","          print(i)\n","\n","        # Used to terminate early, remove.\n","        '''\n","        if batch_idx >= 100: \n","            break\n","        '''\n","        \n","df = pd.DataFrame.from_dict(results)\n","df.to_csv(file, index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ks-UHJf18Vqj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qubhlwR18Vqk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}